{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe776c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinpnjt/env/lib/python3.12/site-packages/backtesting/_plotting.py:55: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support, such as old IDEs. Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
      "  warnings.warn('Jupyter Notebook detected. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"cae6267b-3b03-4aa9-a094-40228942f85f\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"cae6267b-3b03-4aa9-a094-40228942f85f\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.8.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"cae6267b-3b03-4aa9-a094-40228942f85f\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"cae6267b-3b03-4aa9-a094-40228942f85f\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.8.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"cae6267b-3b03-4aa9-a094-40228942f85f\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "from backtesting import Backtest, Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e31150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── User settings ─────────────────────────────────────────────────────────────\n",
    "# SYMBOL       = \"EURUSD=X\"   # e.g. \"EURUSD=X\", \"USDJPY=X\", \"XAUUSD=X\", \"BTC-USD\"\n",
    "# START        = \"2024-01-01\" # pull ~2 years; adjust as needed\n",
    "# INTERVAL     = \"4h\"         # 4-hour candles\n",
    "# CASH         = 10_000\n",
    "# COMMISSION   = 0.000       # 0.02%\n",
    "\n",
    "# Ichimoku params (defaults)\n",
    "TENKAN       = 9\n",
    "KIJUN        = 26\n",
    "SENKOU_B     = 52\n",
    "\n",
    "# Risk settings (ATR-based)\n",
    "ATR_LEN      = 14\n",
    "ATR_MULT_SL  = 2.0          # SL = ATR * this\n",
    "ATR_MULT_TP  = 4.0          # TP = ATR * this  (≈ 2R by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c33bfa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(symbol: str, start: str, end:str, interval: str) -> pd.DataFrame:\n",
    "    df = yf.download(symbol, start=start, end=end, interval=interval,\n",
    "                     auto_adjust=True, progress=False, threads=False)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data returned for {symbol} @ {interval}. \"\n",
    "                         \"Try a different symbol/interval or earlier START.\")\n",
    "\n",
    "    # Handle new yfinance MultiIndex format (Price, Ticker)\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        # Extract the \"Price\" level for the requested symbol\n",
    "        try:\n",
    "            df = df.xs(symbol, axis=1, level=1)  # Keep only this ticker’s data\n",
    "        except KeyError:\n",
    "            # Some yfinance versions put symbol uppercase/lowercase differently\n",
    "            possible = [lev for lev in df.columns.levels[1]]\n",
    "            raise KeyError(f\"Symbol '{symbol}' not found in MultiIndex columns. \"\n",
    "                           f\"Available: {possible}\")\n",
    "    else:\n",
    "        # Older yfinance already returns flat columns\n",
    "        pass\n",
    "\n",
    "    # Ensure column names are standardized\n",
    "    df.columns = [c.title() for c in df.columns]\n",
    "    return df.dropna()\n",
    "\n",
    "def _ichimoku_manual(df: pd.DataFrame, tenkan: int, kijun: int, senkou_b: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Bias-safe Ichimoku (raw values for signal logic).\n",
    "    - SpanA/SpanB are UNshifted.\n",
    "    - Chikou: provide plotting version ONLY; logic uses past-aligned booleans.\n",
    "    \"\"\"\n",
    "    h, l, c = df[\"High\"], df[\"Low\"], df[\"Close\"]\n",
    "\n",
    "    tenkan_line = (h.rolling(tenkan).max() + l.rolling(tenkan).min()) / 2.0\n",
    "    kijun_line  = (h.rolling(kijun ).max() + l.rolling(kijun ).min()) / 2.0\n",
    "    span_a_raw  = (tenkan_line + kijun_line) / 2.0                  # raw (no forward shift)\n",
    "    span_b_raw  = (h.rolling(senkou_b).max() + l.rolling(senkou_b).min()) / 2.0  # raw\n",
    "\n",
    "    # For charts only: the classic \"lagging\" line plotted back kijun periods.\n",
    "    # DO NOT use ich_chikou_plot in entry/exit logic.\n",
    "    chikou_plot = c.shift(-kijun)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"ich_tenkan\"]       = tenkan_line\n",
    "    out[\"ich_kijun\"]        = kijun_line\n",
    "    out[\"ich_spanA\"]        = span_a_raw\n",
    "    out[\"ich_spanB\"]        = span_b_raw\n",
    "    out[\"ich_chikou_plot\"]  = chikou_plot\n",
    "\n",
    "    # Bias-free chikou confirmations (optional for logic):\n",
    "    cloud_top = out[[\"ich_spanA\", \"ich_spanB\"]].max(axis=1)\n",
    "    cloud_bot = out[[\"ich_spanA\", \"ich_spanB\"]].min(axis=1)\n",
    "\n",
    "    # At time t, check what was true 26 bars ago: close[t-26] vs cloud[t-26]\n",
    "    out[\"chik_ok_long\"]  = c.shift(kijun) > cloud_top.shift(kijun)\n",
    "    out[\"chik_ok_short\"] = c.shift(kijun) < cloud_bot.shift(kijun)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_ichimoku(df: pd.DataFrame,\n",
    "                 tenkan: int = TENKAN,\n",
    "                 kijun: int = KIJUN,\n",
    "                 senkou_b: int = SENKOU_B) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build bias-safe Ichimoku columns for SIGNAL logic.\n",
    "    - Prefer pandas_ta for Tenkan/Kijun if available, but compute SpanA/SpanB ourselves (raw).\n",
    "    - Never use a forward-shifted SpanA/SpanB.\n",
    "    - Provide chikou *plotting* series and bias-free chikou booleans for logic.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Try to get Tenkan & Kijun from pandas_ta (core frame only), but do NOT trust spans blindly.\n",
    "    tenkan_series, kijun_series = None, None\n",
    "    try:\n",
    "        res = ta.ichimoku(\n",
    "            high=out[\"High\"], low=out[\"Low\"], close=out[\"Close\"],\n",
    "            tenkan=tenkan, kijun=kijun, senkou=senkou_b\n",
    "        )\n",
    "        ichi_core = res[0] if isinstance(res, tuple) else (res if isinstance(res, pd.DataFrame) else None)\n",
    "\n",
    "        if isinstance(ichi_core, pd.DataFrame) and not ichi_core.empty:\n",
    "            # Be explicit: pick exact ITS_/IKS_ columns for our periods only.\n",
    "            its_col = f\"ITS_{tenkan}\"\n",
    "            iks_col = f\"IKS_{kijun}\"\n",
    "            if its_col in ichi_core.columns and iks_col in ichi_core.columns:\n",
    "                tenkan_series = ichi_core[its_col]\n",
    "                kijun_series  = ichi_core[iks_col]\n",
    "    except Exception:\n",
    "        pass  # fall back to manual fully\n",
    "\n",
    "    # If ta not available or columns missing, compute manually.\n",
    "    if tenkan_series is None or kijun_series is None:\n",
    "        h, l = out[\"High\"], out[\"Low\"]\n",
    "        tenkan_series = (h.rolling(tenkan).max() + l.rolling(tenkan).min()) / 2.0\n",
    "        kijun_series  = (h.rolling(kijun ).max() + l.rolling(kijun ).min()) / 2.0\n",
    "\n",
    "    # Compute raw spans (no forward shift)\n",
    "    h, l, c = out[\"High\"], out[\"Low\"], out[\"Close\"]\n",
    "    span_a_raw = (tenkan_series + kijun_series) / 2.0\n",
    "    span_b_raw = (h.rolling(senkou_b).max() + l.rolling(senkou_b).min()) / 2.0\n",
    "\n",
    "    out[\"ich_tenkan\"] = tenkan_series\n",
    "    out[\"ich_kijun\"]  = kijun_series\n",
    "    out[\"ich_spanA\"]  = span_a_raw\n",
    "    out[\"ich_spanB\"]  = span_b_raw\n",
    "\n",
    "    # Plotting-only lagging line:\n",
    "    out[\"ich_chikou_plot\"] = c.shift(-kijun)\n",
    "\n",
    "    # Bias-free chikou confirmations for logic:\n",
    "    cloud_top = out[[\"ich_spanA\", \"ich_spanB\"]].max(axis=1)\n",
    "    cloud_bot = out[[\"ich_spanA\", \"ich_spanB\"]].min(axis=1)\n",
    "    out[\"chik_ok_long\"]  = c.shift(kijun) > cloud_top.shift(kijun)\n",
    "    out[\"chik_ok_short\"] = c.shift(kijun) < cloud_bot.shift(kijun)\n",
    "\n",
    "    # ATR\n",
    "    out[\"ATR\"] = ta.atr(out[\"High\"], out[\"Low\"], out[\"Close\"], length=ATR_LEN)\n",
    "\n",
    "    # Drop warmup NaNs (needs max of 52 and ATR_LEN history)\n",
    "    cols_needed = [\"ich_tenkan\",\"ich_kijun\",\"ich_spanA\",\"ich_spanB\",\"ATR\",\"chik_ok_long\",\"chik_ok_short\"]\n",
    "    out = out.dropna(subset=cols_needed)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc596584-d450-4aae-a56a-de69527cdc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sample forex data...\n",
      "Creating sample data for demonstration...\n",
      "Using sample data for development\n",
      "                Open      High       Low     Close   Volume\n",
      "2024-01-01  0.650000  0.650650  0.649350  0.650000  1000000\n",
      "2024-01-02  0.651614  0.652266  0.650963  0.651614  1000000\n",
      "2024-01-03  0.651164  0.651815  0.650513  0.651164  1000000\n",
      "2024-01-04  0.653273  0.653926  0.652619  0.653273  1000000\n",
      "2024-01-05  0.658247  0.658906  0.657589  0.658247  1000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "def fetch_forex_from_csv():\n",
    "    \"\"\"\n",
    "    Alternatif: Download data dari sumber online\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Contoh URL data forex (ganti dengan sumber yang reliable)\n",
    "        url = \"https://www.ecb.europa.eu/stats/eurofxref/eurofxref-hist.zip\"\n",
    "        \n",
    "        # Atau gunakan data sample lokal\n",
    "        print(\"Creating sample data for demonstration...\")\n",
    "        \n",
    "        # Buat data sample AUD/USD\n",
    "        dates = pd.date_range(start=START, end=END, freq='D')\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Simulasi pergerakan harga AUD/USD\n",
    "        prices = [0.65]  # Start around 0.65\n",
    "        for i in range(1, len(dates)):\n",
    "            change = np.random.normal(0, 0.005)\n",
    "            new_price = prices[-1] * (1 + change)\n",
    "            prices.append(new_price)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'Open': prices,\n",
    "            'High': [p * 1.001 for p in prices],\n",
    "            'Low': [p * 0.999 for p in prices],\n",
    "            'Close': prices,\n",
    "            'Volume': [1000000] * len(prices)\n",
    "        }, index=dates)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error with alternative source: {e}\")\n",
    "        return None\n",
    "\n",
    "# Coba buat data sample\n",
    "print(\"Creating sample forex data...\")\n",
    "df_sample = fetch_forex_from_csv()\n",
    "\n",
    "if df_sample is not None:\n",
    "    df = df_sample\n",
    "    print(\"Using sample data for development\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91b9fa78-9a26-4e5e-bbc5-d6f69af3ea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AUDUSD']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "\n",
      "1 Failed download:\n",
      "['AUDUSD']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying alternative symbol: AUDUSD\n",
      "Error fetching data: No data returned for AUDUSD @ 1d. Try a different symbol/interval or check date range.\n"
     ]
    }
   ],
   "source": [
    "# Opsi 1: Gunakan timeframe yang lebih pendek\n",
    "START = \"2024-01-01\"  # Hanya 9 bulan terakhir\n",
    "END = \"2024-10-01\"\n",
    "\n",
    "# Opsi 2: Gunakan interval daily\n",
    "INTERVAL = \"1d\"  # Daily data lebih reliable\n",
    "\n",
    "# Opsi 3: Coba simbol alternatif\n",
    "SYMBOL = \"AUDUSD\"  # Tanpa =X\n",
    "\n",
    "df = fetch_data(symbol=SYMBOL, start=START, end=END, interval=INTERVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bfc3622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['USDCHF=X']: YFPricesMissingError('possibly delisted; no price data found  (4h 2023-10-01 -> 2024-10-01) (Yahoo error = \"4h data not available for startTime=1696114800 and endTime=1727737200. The requested range must be within the last 730 days.\")')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No data returned for USDCHF=X @ 4h. Try a different symbol/interval or earlier START.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m CASH         = \u001b[32m1000000\u001b[39m\n\u001b[32m      6\u001b[39m COMMISSION   = \u001b[32m0.0002\u001b[39m      \u001b[38;5;66;03m# 0.02%\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSYMBOL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSTART\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEND\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# df = add_ichimoku(df, TENKAN, KIJUN, SENKOU_B)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# df[\"EMA\"] = ta.ema(close=df[\"Close\"], length=100)\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# df\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mfetch_data\u001b[39m\u001b[34m(symbol, start, end, interval)\u001b[39m\n\u001b[32m      2\u001b[39m df = yf.download(symbol, start=start, end=end, interval=interval,\n\u001b[32m      3\u001b[39m                  auto_adjust=\u001b[38;5;28;01mTrue\u001b[39;00m, progress=\u001b[38;5;28;01mFalse\u001b[39;00m, threads=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df.empty:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo data returned for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m @ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterval\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mTry a different symbol/interval or earlier START.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Handle new yfinance MultiIndex format (Price, Ticker)\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df.columns, pd.MultiIndex):\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Extract the \"Price\" level for the requested symbol\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: No data returned for USDCHF=X @ 4h. Try a different symbol/interval or earlier START."
     ]
    }
   ],
   "source": [
    "SYMBOL       = \"USDCHF=X\"  #GBPUSD=X  # e.g. \"EURUSD=X\", \"USDJPY=X\", \"XAUUSD=X\", \"BTC-USD\", GBPJPY=X \n",
    "START        = \"2023-10-01\" # pull ~1-2 years; adjust as needed\n",
    "END         = \"2024-10-01\" \n",
    "INTERVAL     = \"4h\"         # 4-hour candles\n",
    "CASH         = 1000000\n",
    "COMMISSION   = 0.0002      # 0.02%\n",
    "df = fetch_data(symbol=SYMBOL, start=START, end=END, interval=INTERVAL)\n",
    "# df = add_ichimoku(df, TENKAN, KIJUN, SENKOU_B)\n",
    "# df[\"EMA\"] = ta.ema(close=df[\"Close\"], length=100)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MovingAverageSignal(df: pd.DataFrame, back_candles: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a single-column EMA trend signal to the DataFrame.\n",
    "\n",
    "    Rules (evaluated per bar, using *only* current/past data):\n",
    "      +1 (uptrend):   For the window [t-back_candles .. t], EVERY bar has\n",
    "                      Open > EMA and Close > EMA.\n",
    "      -1 (downtrend): For the same window, EVERY bar has\n",
    "                      Open < EMA and Close < EMA.\n",
    "       0 otherwise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns: 'Open', 'Close', 'EMA'.\n",
    "    back_candles : int\n",
    "        Number of *previous* candles to include in addition to the current one.\n",
    "        Effective window size = back_candles + 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copy of df with a new integer column 'EMA_signal' in {-1, 0, +1}.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    required = [\"Open\", \"Close\", \"EMA\"]\n",
    "    missing = [c for c in required if c not in out.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    # Window size: current bar + `back_candles` bars behind it\n",
    "    w = int(back_candles) + 1\n",
    "    if w <= 0:\n",
    "        raise ValueError(\"back_candles must be >= 0\")\n",
    "\n",
    "    # Booleans per-bar relative to EMA\n",
    "    above = (out[\"Open\"] > out[\"EMA\"]) & (out[\"Close\"] > out[\"EMA\"])\n",
    "    below = (out[\"Open\"] < out[\"EMA\"]) & (out[\"Close\"] < out[\"EMA\"])\n",
    "\n",
    "    # \"All true in the last w bars\" via rolling sum == w\n",
    "    above_all = (above.rolling(w, min_periods=w).sum() == w)\n",
    "    below_all = (below.rolling(w, min_periods=w).sum() == w)\n",
    "\n",
    "    # Single signal column\n",
    "    signal = np.where(above_all, 1, np.where(below_all, -1, 0)).astype(int)\n",
    "    out[\"EMA_signal\"] = signal\n",
    "\n",
    "    return out\n",
    "\n",
    "df = MovingAverageSignal(df, back_candles=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e00e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def createSignals(df: pd.DataFrame,\n",
    "                  lookback_window: int = 10,\n",
    "                  min_confirm: int = 5,\n",
    "                  cloud_top_cols: tuple = (\"ich_spanA\", \"ich_spanB\"),\n",
    "                  ema_signal_col: str = \"EMA_signal\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Produce a single 'signal' column aligned with EMA trend:\n",
    "      +1 (long):  Ichimoku 'pierce-up' + enough prior bars entirely ABOVE cloud\n",
    "                   AND EMA_signal == +1\n",
    "      -1 (short): Ichimoku 'pierce-down' + enough prior bars entirely BELOW cloud\n",
    "                   AND EMA_signal == -1\n",
    "       0 (none): otherwise\n",
    "\n",
    "    Notes:\n",
    "    - Uses only current/past data (no look-ahead).\n",
    "    - If both long and short conditions were somehow true, resolve to 0.\n",
    "    \"\"\"\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    # --- Requirements ---\n",
    "    req_cols = [\"Open\", \"Close\", cloud_top_cols[0], cloud_top_cols[1], ema_signal_col]\n",
    "    missing = [c for c in req_cols if c not in out.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    # Cloud boundaries\n",
    "    spanA_col, spanB_col = cloud_top_cols\n",
    "    cloud_top = out[[spanA_col, spanB_col]].max(axis=1)\n",
    "    cloud_bot = out[[spanA_col, spanB_col]].min(axis=1)\n",
    "\n",
    "    # Candles entirely above/below cloud\n",
    "    above_cloud = (out[\"Open\"] > cloud_top) & (out[\"Close\"] > cloud_top)\n",
    "    below_cloud = (out[\"Open\"] < cloud_bot) & (out[\"Close\"] < cloud_bot)\n",
    "\n",
    "    above_count = above_cloud.rolling(lookback_window, min_periods=lookback_window).sum()\n",
    "    below_count = below_cloud.rolling(lookback_window, min_periods=lookback_window).sum()\n",
    "\n",
    "    # Current-bar pierce conditions\n",
    "    pierce_up   = (out[\"Open\"] < cloud_top) & (out[\"Close\"] > cloud_top)\n",
    "    pierce_down = (out[\"Open\"] > cloud_bot) & (out[\"Close\"] < cloud_bot)\n",
    "\n",
    "    # Trend confirmations\n",
    "    up_trend_ok   = above_count >= min_confirm\n",
    "    down_trend_ok = below_count >= min_confirm\n",
    "\n",
    "    # EMA alignment\n",
    "    ema_up   = (out[ema_signal_col] == 1)\n",
    "    ema_down = (out[ema_signal_col] == -1)\n",
    "\n",
    "    # Final conditions (Ichimoku + EMA alignment)\n",
    "    long_cond  = up_trend_ok & pierce_up   & ema_up\n",
    "    short_cond = down_trend_ok & pierce_down & ema_down\n",
    "\n",
    "    # Single signal column\n",
    "    signal = np.where(long_cond & ~short_cond,  1,\n",
    "             np.where(short_cond & ~long_cond, -1, 0)).astype(int)\n",
    "\n",
    "    out[\"signal\"] = signal\n",
    "    return out\n",
    "\n",
    "df = createSignals(df, lookback_window=10, min_confirm=5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ca32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plot_signals_ichimoku(\n",
    "    df: pd.DataFrame,\n",
    "    start_idx: int,\n",
    "    end_idx: int,\n",
    "    show_cloud: bool = True,\n",
    "    title: str | None = None,\n",
    "    offset_frac: float = 0.006,\n",
    "    marker_size: int = 12,\n",
    "    fig_width: int = 1000,\n",
    "    fig_height: int = 700,\n",
    "    show: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a candlestick slice with optional Ichimoku cloud, EMA, and signal markers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Full dataframe (indexed by datetime or integer).\n",
    "    start_idx, end_idx : int\n",
    "        Inclusive slice bounds on row positions (iloc-based).\n",
    "    show_cloud : bool\n",
    "        If True, overlays ich_spanA/B cloud.\n",
    "    title : str | None\n",
    "        Optional plot title.\n",
    "    offset_frac : float\n",
    "        Fraction of price used to nudge triangle markers away from candle extremes.\n",
    "    marker_size : int\n",
    "        Size of signal triangle markers.\n",
    "    fig_width, fig_height : int\n",
    "        Dimensions of the Plotly figure (in pixels).\n",
    "    show : bool\n",
    "        If True, immediately render the figure; otherwise just return it.\n",
    "    \"\"\"\n",
    "\n",
    "    # Slice\n",
    "    data = df.iloc[start_idx:end_idx + 1].copy()\n",
    "    if data.empty:\n",
    "        raise ValueError(\"Selected slice is empty. Check start_idx/end_idx.\")\n",
    "\n",
    "    for col in [\"Open\",\"High\",\"Low\",\"Close\",\"signal\"]:\n",
    "        if col not in data.columns:\n",
    "            raise KeyError(f\"Missing required column: {col}\")\n",
    "\n",
    "    x = data.index\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Candles\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=x,\n",
    "        open=data[\"Open\"],\n",
    "        high=data[\"High\"],\n",
    "        low=data[\"Low\"],\n",
    "        close=data[\"Close\"],\n",
    "        name=\"Price\"\n",
    "    ))\n",
    "\n",
    "    # Ichimoku cloud\n",
    "    if show_cloud:\n",
    "        for col in [\"ich_spanA\",\"ich_spanB\"]:\n",
    "            if col not in data.columns:\n",
    "                raise KeyError(f\"show_cloud=True but missing column: {col}\")\n",
    "        spanA, spanB = data[\"ich_spanA\"], data[\"ich_spanB\"]\n",
    "        fig.add_trace(go.Scatter(x=x, y=spanA, mode=\"lines\", name=\"Span A\", line=dict(width=1)))\n",
    "        fig.add_trace(go.Scatter(x=x, y=spanB, mode=\"lines\", name=\"Span B\",\n",
    "                                 fill=\"tonexty\", opacity=0.2, line=dict(width=1)))\n",
    "\n",
    "    # EMA\n",
    "    if \"EMA\" in data.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=data[\"EMA\"], mode=\"lines\", name=\"EMA\",\n",
    "            line=dict(color=\"blue\", width=2, dash=\"dot\")\n",
    "        ))\n",
    "\n",
    "    # Offset for markers\n",
    "    pad = offset_frac * data[\"Close\"].abs().replace(0, np.nan).fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "    # Long markers\n",
    "    bull = data[\"signal\"] == 1\n",
    "    if bull.any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x[bull],\n",
    "            y=(data.loc[bull, \"Low\"] - pad.loc[bull]),\n",
    "            mode=\"markers\",\n",
    "            name=\"Long signal\",\n",
    "            marker=dict(symbol=\"triangle-up\", size=marker_size, color=\"green\"),\n",
    "            hovertemplate=\"Long signal<br>%{x|%Y-%m-%d %H:%M}<extra></extra>\"\n",
    "        ))\n",
    "\n",
    "    # Short markers\n",
    "    bear = data[\"signal\"] == -1\n",
    "    if bear.any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x[bear],\n",
    "            y=(data.loc[bear, \"High\"] + pad.loc[bear]),\n",
    "            mode=\"markers\",\n",
    "            name=\"Short signal\",\n",
    "            marker=dict(symbol=\"triangle-down\", size=marker_size, color=\"red\"),\n",
    "            hovertemplate=\"Short signal<br>%{x|%Y-%m-%d %H:%M}<extra></extra>\"\n",
    "        ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=title or \"Signals, Ichimoku & EMA\",\n",
    "        width=fig_width,\n",
    "        height=fig_height,\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Price\",\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        hovermode=\"x unified\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.01, xanchor=\"left\", x=0)\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(showgrid=True)\n",
    "    fig.update_yaxes(showgrid=True)\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "plot_signals_ichimoku(df=df, start_idx=350, end_idx=450, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting import Strategy\n",
    "\n",
    "class SignalStrategy(Strategy):\n",
    "    \"\"\"Generic signal-based strategy with ATR SL and RR-based TP.\"\"\"\n",
    "    \n",
    "    atr_mult_sl: float = 1.5   # stop-loss distance = atr * atr_mult_sl\n",
    "    rr_mult_tp:  float = 2.0  # take-profit distance = SL distance * rr_mult_tp\n",
    "\n",
    "    def init(self):\n",
    "        return\n",
    "\n",
    "    def next(self):\n",
    "        i = -1\n",
    "        signal = int(self.data.signal[i])   # +1 long, -1 short, 0 none\n",
    "        close  = float(self.data.Close[i])\n",
    "        atr    = float(self.data.ATR[i])\n",
    "\n",
    "        if not (atr > 0):\n",
    "            return\n",
    "\n",
    "        # --- manage open trades ---\n",
    "        if self.position:\n",
    "            # Do nothing, let SL/TP handle exits\n",
    "            return\n",
    "\n",
    "        # --- new entry ---\n",
    "        sl_dist = atr * self.atr_mult_sl\n",
    "        tp_dist = sl_dist * self.rr_mult_tp\n",
    "\n",
    "        if signal == 1:  # long entry\n",
    "            sl = close - sl_dist\n",
    "            tp = close + tp_dist\n",
    "            self.buy(size=0.99, sl=sl, tp=tp)\n",
    "\n",
    "        elif signal == -1:  # short entry\n",
    "            sl = close + sl_dist\n",
    "            tp = close - tp_dist\n",
    "            self.sell(size=0.99, sl=sl, tp=tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_backtest(symbol: str,\n",
    "                 start: str,\n",
    "                 end: str,\n",
    "                 interval: str,\n",
    "                 cash: float,\n",
    "                 commission: float,\n",
    "                 show_plot: bool = True):\n",
    "\n",
    "    df = fetch_data(symbol, start, end, interval)\n",
    "    df = add_ichimoku(df, TENKAN, KIJUN, SENKOU_B)\n",
    "    df[\"ATR\"] = ta.atr(df[\"High\"], df[\"Low\"], df[\"Close\"], length=ATR_LEN)\n",
    "    df[\"EMA\"] = ta.ema(df.Close, length=100)\n",
    "\n",
    "    # Make sure your EMA_signal + Ichimoku_signal were created beforehand:\n",
    "    df = MovingAverageSignal(df, back_candles=7)\n",
    "    df = createSignals(df, lookback_window=10, min_confirm=7)\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    bt = Backtest(\n",
    "        df,\n",
    "        SignalStrategy,\n",
    "        cash=cash,\n",
    "        commission=commission,\n",
    "        trade_on_close=True,\n",
    "        exclusive_orders=True,\n",
    "        margin=1/10,\n",
    "    )\n",
    "\n",
    "    stats = bt.run()\n",
    "    print(f\"\\n=== {symbol} — Signal Strategy ===\")\n",
    "    print(stats)\n",
    "\n",
    "    if show_plot:\n",
    "        bt.plot(open_browser=False)\n",
    "    return stats,df,bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples:\n",
    "# - FX majors:  \"EURUSD=X\", \"USDJPY=X\", \"GBPUSD=X\"\n",
    "# - Gold spot:  \"XAUUSD=X\"\n",
    "# - Crypto:     \"BTC-USD\"\n",
    "\n",
    "# ── User settings ─────────────────────────────────────────────────────────────\n",
    "SYMBOL       = \"USDCHF=X\" #AUDUSD=X\" #\"USDCHF=X\"  GBPUSD=X  # e.g. \"EURUSD=X\", \"USDJPY=X\", \"XAUUSD=X\", \"BTC-USD\", GBPJPY=X \n",
    "START        = \"2023-10-01\" # pull ~1-2 years; adjust as needed\n",
    "END         = \"2024-10-01\" \n",
    "INTERVAL     = \"4h\"         # 4-hour candles\n",
    "CASH         = 1000000\n",
    "COMMISSION   = 0.0002      # 0.02%\n",
    "\n",
    "stats, df, bt = run_backtest(symbol=SYMBOL, start=START, end=END, interval=INTERVAL,\n",
    "                cash=CASH, commission=COMMISSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Basket to test ────────────────────────────────────────────────────────────\n",
    "SYMBOLS = [\n",
    "    # FX majors\n",
    "    \"EURUSD=X\", \"USDJPY=X\", \"GBPUSD=X\", \"AUDUSD=X\", \"USDCHF=X\", \"USDCAD=X\", \"NZDUSD=X\"\n",
    "]\n",
    "\n",
    "# Global settings (override if you wish)\n",
    "START      = \"2023-10-01\"\n",
    "END        = \"2024-10-01\"\n",
    "INTERVAL   = \"4h\"\n",
    "CASH       = 1_000_000\n",
    "COMMISSION = 0.0002\n",
    "\n",
    "def run_all_assets(symbols=SYMBOLS,\n",
    "                   start=START, end=END, interval=INTERVAL,\n",
    "                   cash=CASH, commission=COMMISSION,\n",
    "                   show_plot=False):\n",
    "    def sget(stats, key, default=np.nan):\n",
    "        try:\n",
    "            return float(stats.get(key, default))\n",
    "        except Exception:\n",
    "            return default\n",
    "\n",
    "    rows = []\n",
    "    for sym in symbols:\n",
    "        try:\n",
    "            res = run_backtest(symbol=sym, start=start, end=end, interval=interval,\n",
    "                               cash=cash, commission=commission, show_plot=show_plot)\n",
    "            stats = res[0] if isinstance(res, (tuple, list)) else res\n",
    "\n",
    "            rows.append({\n",
    "                \"Symbol\": sym,\n",
    "                \"Return [%]\":         sget(stats, \"Return [%]\"),\n",
    "                \"MaxDD [%]\":          sget(stats, \"Max. Drawdown [%]\"),\n",
    "                \"AvgDD [%]\":          sget(stats, \"Avg. Drawdown [%]\"),\n",
    "                \"Win Rate [%]\":       sget(stats, \"Win Rate [%]\"),\n",
    "                \"Trades\":             sget(stats, \"# Trades\"),          # ← correct key\n",
    "                \"Exposure Time [%]\":  sget(stats, \"Exposure Time [%]\"),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {sym}: backtest failed -> {e}\")\n",
    "            rows.append({\n",
    "                \"Symbol\": sym,\n",
    "                \"Return [%]\": np.nan, \"MaxDD [%]\": np.nan, \"AvgDD [%]\": np.nan,\n",
    "                \"Win Rate [%]\": np.nan, \"Trades\": np.nan, \"Exposure Time [%]\": np.nan\n",
    "            })\n",
    "\n",
    "    df_summary = pd.DataFrame(rows)\n",
    "\n",
    "    # Simple (unweighted) averages ignoring NaNs\n",
    "    avg_row = {\"Symbol\": \"AVERAGE\"}\n",
    "    for col in [\"Return [%]\", \"MaxDD [%]\", \"AvgDD [%]\", \"Win Rate [%]\", \"Trades\", \"Exposure Time [%]\"]:\n",
    "        avg_row[col] = df_summary[col].mean(skipna=True)\n",
    "\n",
    "    df_summary = pd.concat([df_summary, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "    with pd.option_context(\"display.float_format\", \"{:,.2f}\".format):\n",
    "        print(\"\\n=== Multi-asset backtest summary ===\")\n",
    "        print(df_summary)\n",
    "\n",
    "    return df_summary\n",
    "\n",
    "# Run it\n",
    "summary = run_all_assets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0aa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c141ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build numeric grids\n",
    "atr_values = list(np.arange(1.0, 2.5, 0.1))\n",
    "rr_values  = list(np.arange(1.0, 3.0, 0.1))\n",
    "\n",
    "# Backtest\n",
    "bt = Backtest(\n",
    "    df,\n",
    "    SignalStrategy,\n",
    "    cash=100000,\n",
    "    commission=0.0002,\n",
    "    trade_on_close=True,\n",
    "    exclusive_orders=True,\n",
    "    margin=1/10,\n",
    ")\n",
    "\n",
    "# Optimize. return_heatmap=True yields a DataFrame with all trials.\n",
    "stats, heat = bt.optimize(\n",
    "    atr_mult_sl = atr_values,\n",
    "    rr_mult_tp  = rr_values,\n",
    "    maximize    = \"Return [%]\",\n",
    "    return_heatmap = True,\n",
    ")\n",
    "print(stats._strategy)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c24823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_heatmap(\n",
    "    heat,\n",
    "    metric_name: str = \"Return [%]\",\n",
    "    fig_width: int = 1000,\n",
    "    fig_height: int = 700,\n",
    "    cmap: str = \"Viridis\",\n",
    "    annotate: bool = True,\n",
    "    min_return: float | None = None,\n",
    "    max_return: float | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot an optimization heatmap (ATR x RR) with optional threshold masking.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    heat : pd.Series or pd.DataFrame\n",
    "        If Series: MultiIndex (atr_mult_sl, rr_mult_tp) -> metric values.\n",
    "        If DataFrame: columns must include ['atr_mult_sl','rr_mult_tp', metric_name].\n",
    "    metric_name : str\n",
    "        Metric to display (e.g., 'Return [%]').\n",
    "    fig_width, fig_height : int\n",
    "        Figure size in pixels.\n",
    "    cmap : str\n",
    "        Plotly colorscale.\n",
    "    annotate : bool\n",
    "        Annotate cells with metric numbers.\n",
    "    min_return, max_return : float | None\n",
    "        Inclusive thresholds. Cells outside [min_return, max_return] are blacked out.\n",
    "        If None, the side is unbounded.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fig : plotly.graph_objects.Figure\n",
    "    best_info : dict or None\n",
    "        {'atr': ..., 'rr': ..., 'value': ...} for the best cell within thresholds,\n",
    "        or None if no cell meets the thresholds.\n",
    "    \"\"\"\n",
    "    # --- Normalize input to a pivot (rows=atr_mult_sl, cols=rr_mult_tp) ---\n",
    "    if isinstance(heat, pd.Series):\n",
    "        heat_df = heat.to_frame(name=metric_name).reset_index()\n",
    "    else:\n",
    "        if isinstance(heat.index, pd.MultiIndex) and heat.shape[1] == 1:\n",
    "            heat_df = heat.reset_index()\n",
    "            heat_df.columns = [\"atr_mult_sl\", \"rr_mult_tp\", metric_name]\n",
    "        elif {\"atr_mult_sl\", \"rr_mult_tp\", metric_name}.issubset(heat.columns):\n",
    "            heat_df = heat[[\"atr_mult_sl\", \"rr_mult_tp\", metric_name]].reset_index(drop=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized 'heat' format. Provide a Series or a DataFrame with \"\n",
    "                             \"columns ['atr_mult_sl','rr_mult_tp', metric_name].\")\n",
    "\n",
    "    zdf = (heat_df\n",
    "           .pivot(index=\"atr_mult_sl\", columns=\"rr_mult_tp\", values=metric_name)\n",
    "           .sort_index()\n",
    "           .sort_index(axis=1))\n",
    "\n",
    "    # Numeric axis labels\n",
    "    x_vals = zdf.columns.to_numpy(dtype=float)  # RR multipliers\n",
    "    y_vals = zdf.index.to_numpy(dtype=float)    # ATR multipliers\n",
    "    Z = zdf.values.astype(float)\n",
    "\n",
    "    # --- Build base heatmap (Plotly Express for easy colorbar/labels) ---\n",
    "    fig = px.imshow(\n",
    "        Z,\n",
    "        x=x_vals,\n",
    "        y=y_vals,\n",
    "        aspect=\"auto\",\n",
    "        color_continuous_scale=cmap,\n",
    "        origin=\"lower\",\n",
    "        labels=dict(x=\"RR multiplier (TP = SL × RR)\", y=\"ATR multiplier (SL = ATR × m)\", color=metric_name),\n",
    "        title=f\"Optimization heatmap — {metric_name}\",\n",
    "    )\n",
    "    fig.update_layout(width=fig_width, height=fig_height)\n",
    "\n",
    "    if annotate:\n",
    "        fig.update_traces(\n",
    "            text=np.where(np.isnan(Z), \"\", np.round(Z, 2).astype(str)),\n",
    "            texttemplate=\"%{text}\",\n",
    "            hovertemplate=\"ATR=%{y}<br>RR=%{x}<br>\"+metric_name+\"=%{z}<extra></extra>\"\n",
    "        )\n",
    "\n",
    "    # --- Threshold masking: blackout cells outside [min_return, max_return] ---\n",
    "    mask = np.zeros_like(Z, dtype=float)  # 0 = keep (transparent), 1 = blackout\n",
    "    if (min_return is not None) or (max_return is not None):\n",
    "        lower_ok = (Z >= (min_return if min_return is not None else -np.inf))\n",
    "        upper_ok = (Z <= (max_return if max_return is not None else  np.inf))\n",
    "        in_range = lower_ok & upper_ok\n",
    "        mask = (~in_range).astype(float)\n",
    "\n",
    "        # Add a semi-opaque black overlay for masked cells\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=mask,\n",
    "            x=x_vals,\n",
    "            y=y_vals,\n",
    "            showscale=False,\n",
    "            colorscale=[[0.0, \"rgba(0,0,0,0)\"], [1.0, \"rgba(0,0,0,0.82)\"]],\n",
    "            hoverinfo=\"skip\",\n",
    "        ))\n",
    "\n",
    "        # --- Find best cell within thresholds (maximize metric) ---\n",
    "        if in_range.any():\n",
    "            # Get index of max within allowed region\n",
    "            Z_masked = np.where(in_range, Z, -np.inf)\n",
    "            best_flat = np.nanargmax(Z_masked)\n",
    "            best_i, best_j = np.unravel_index(best_flat, Z_masked.shape)\n",
    "            best_info = {\"atr\": float(y_vals[best_i]), \"rr\": float(x_vals[best_j]), \"value\": float(Z[best_i, best_j])}\n",
    "\n",
    "            # Add annotation marker\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[x_vals[best_j]], y=[y_vals[best_i]],\n",
    "                mode=\"markers+text\",\n",
    "                text=[f\"★ {best_info['value']:.2f}\"],\n",
    "                textposition=\"top center\",\n",
    "                marker=dict(size=12, color=\"white\", line=dict(width=2, color=\"black\")),\n",
    "                name=\"Best in range\"\n",
    "            ))\n",
    "        else:\n",
    "            best_info = None\n",
    "    else:\n",
    "        # No thresholds -> best over all cells (optional)\n",
    "        best_flat = np.nanargmax(Z)\n",
    "        best_i, best_j = np.unravel_index(best_flat, Z.shape)\n",
    "        best_info = {\"atr\": float(y_vals[best_i]), \"rr\": float(x_vals[best_j]), \"value\": float(Z[best_i, best_j])}\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[x_vals[best_j]], y=[y_vals[best_i]],\n",
    "            mode=\"markers+text\",\n",
    "            text=[f\"★ {best_info['value']:.2f}\"],\n",
    "            textposition=\"top center\",\n",
    "            marker=dict(size=12, color=\"white\", line=dict(width=2, color=\"black\")),\n",
    "            name=\"Best overall\"\n",
    "        ))\n",
    "\n",
    "    # Category ticks for neat labels\n",
    "    fig.update_xaxes(\n",
    "        type=\"category\",\n",
    "        tickmode=\"array\",\n",
    "        tickvals=x_vals,\n",
    "        ticktext=[f\"{v:.1f}\" for v in x_vals],\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        type=\"category\",\n",
    "        tickmode=\"array\",\n",
    "        tickvals=y_vals,\n",
    "        ticktext=[f\"{v:.1f}\" for v in y_vals],\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_heatmap(heat, metric_name=\"Return [%]\", min_return=1, max_return=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_ichimoku(\n",
    "    df: pd.DataFrame,\n",
    "    title: str = \"Ichimoku Cloud (4H)\",\n",
    "    kijun_periods: int = 26,\n",
    "    shift_cloud_forward: bool = True,\n",
    "    show_chikou: bool = True,\n",
    "    show_atr: bool = False,\n",
    "    cloud_eps: float | None = None,  # tolerance to avoid rapid bull/bear flipping\n",
    "):\n",
    "    \"\"\"\n",
    "    Expects columns:\n",
    "      ['Open','High','Low','Close','Volume','ich_tenkan','ich_kijun',\n",
    "       'ich_spanA','ich_spanB','ich_chikou','ATR']\n",
    "    Index must be a DatetimeIndex (tz-aware is fine).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if df.index.tz is None:\n",
    "        df.index = df.index.tz_localize(\"UTC\")\n",
    "\n",
    "    # Derive a sensible default tolerance if not set (tiny fraction of price)\n",
    "    if cloud_eps is None:\n",
    "        cloud_eps = max(1e-8, float(df[\"Close\"].abs().median()) * 1e-6)\n",
    "\n",
    "    # Bar spacing (assumes regular series)\n",
    "    if len(df.index) >= 2:\n",
    "        bar_delta = pd.Series(df.index).diff().median()\n",
    "        if pd.isna(bar_delta):\n",
    "            bar_delta = pd.Timedelta(hours=4)\n",
    "    else:\n",
    "        bar_delta = pd.Timedelta(hours=4)\n",
    "\n",
    "    x_main = df.index\n",
    "    x_cloud = x_main + kijun_periods * bar_delta if shift_cloud_forward else x_main\n",
    "    x_chikou = x_main - kijun_periods * bar_delta\n",
    "\n",
    "    spanA = df[\"ich_spanA\"]\n",
    "    spanB = df[\"ich_spanB\"]\n",
    "\n",
    "    # Masks with tolerance to reduce flicker\n",
    "    diff = spanA - spanB\n",
    "    bull_mask = diff > cloud_eps\n",
    "    bear_mask = diff < -cloud_eps\n",
    "    # Treat very-flat parts (|diff|<=eps) as continuation of the previous regime\n",
    "    flat_mask = ~(bull_mask | bear_mask)\n",
    "    regime = pd.Series(np.where(bull_mask, 1, np.where(bear_mask, -1, 0)), index=df.index)\n",
    "    # forward/backward fill flats\n",
    "    regime = regime.replace(0, np.nan).ffill().bfill().fillna(0).astype(int)\n",
    "    bull_mask = regime == 1\n",
    "    bear_mask = regime == -1\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Candles\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=x_main, open=df[\"Open\"], high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"],\n",
    "        name=\"Price\", increasing_line_color=\"#26a69a\", decreasing_line_color=\"#ef5350\"\n",
    "    ))\n",
    "\n",
    "    # Tenkan & Kijun\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_main, y=df[\"ich_tenkan\"], name=\"Tenkan\", mode=\"lines\",\n",
    "        line=dict(width=1.5, color=\"#2962ff\")\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_main, y=df[\"ich_kijun\"], name=\"Kijun\", mode=\"lines\",\n",
    "        line=dict(width=1.5, color=\"#ff6d00\")\n",
    "    ))\n",
    "\n",
    "    # Helper: add filled cloud segments for contiguous True blocks\n",
    "    def add_cloud_segments(mask: pd.Series, fillcolor: str, showlabel: str):\n",
    "        # group contiguous blocks where mask is True\n",
    "        grp_id = (mask != mask.shift()).cumsum()\n",
    "        first_legend = True\n",
    "        for g, sub in mask.groupby(grp_id):\n",
    "            if not sub.iloc[0]:  # we only draw for True segments\n",
    "                continue\n",
    "            idx = sub.index\n",
    "            xa = x_cloud[df.index.get_indexer_for(idx)]\n",
    "            ya_top = spanA.loc[idx]\n",
    "            yb_bot = spanB.loc[idx]\n",
    "\n",
    "            # Upper line (SpanA) for this block\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=xa, y=ya_top, mode=\"lines\",\n",
    "                line=dict(width=1, color=\"rgba(33,150,243,0.7)\"),\n",
    "                showlegend=first_legend, name=showlabel\n",
    "            ))\n",
    "            # Lower line (SpanB) + fill to previous\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=xa, y=yb_bot, mode=\"lines\",\n",
    "                line=dict(width=1, color=\"rgba(244,67,54,0.7)\"),\n",
    "                fill=\"tonexty\", fillcolor=fillcolor,\n",
    "                showlegend=False, hoverinfo=\"x+y\"\n",
    "            ))\n",
    "            first_legend = False\n",
    "\n",
    "    # Bullish (green) and Bearish (red) cloud segments\n",
    "    add_cloud_segments(bull_mask, fillcolor=\"rgba(0,200,0,0.18)\", showlabel=\"Cloud (Bull)\")\n",
    "    add_cloud_segments(bear_mask, fillcolor=\"rgba(200,0,0,0.18)\", showlabel=\"Cloud (Bear)\")\n",
    "\n",
    "    # Chikou span\n",
    "    if show_chikou and \"ich_chikou\" in df.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_chikou, y=df[\"ich_chikou\"], name=\"Chikou\",\n",
    "            mode=\"lines\", line=dict(width=1.2, color=\"#7b1fa2\", dash=\"dot\")\n",
    "        ))\n",
    "\n",
    "    # ATR (optional, secondary y)\n",
    "    if show_atr and \"ATR\" in df.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_main, y=df[\"ATR\"], name=\"ATR\",\n",
    "            mode=\"lines\", line=dict(width=1.2, color=\"#455a64\"), yaxis=\"y2\"\n",
    "        ))\n",
    "        fig.update_layout(yaxis2=dict(title=\"ATR\", overlaying=\"y\", side=\"right\", showgrid=False))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis=dict(title=\"Time\", rangeslider=dict(visible=False)),\n",
    "        yaxis=dict(title=\"Price\"),\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    "        template=\"plotly_white\",\n",
    "        margin=dict(l=40, r=40, t=60, b=40),\n",
    "        hovermode=\"x unified\",\n",
    "        width=1000,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ichimoku(\n",
    "    df[250:350],\n",
    "    title=\"EURUSD 4H — Ichimoku\",\n",
    "    kijun_periods=26,\n",
    "    shift_cloud_forward=False,   # True for classic look\n",
    "    show_chikou=True,\n",
    "    show_atr=False,\n",
    "    cloud_eps=None  # or a value like 1e-5\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7344f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
